{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nYEj5CeCqbTY"
      },
      "outputs": [],
      "source": [
        "#@title [0] Keep Colab Alive</font>\n",
        "#@markdown This cell runs a JS code that automatically presses the reconnect button in every 60 seconds to avoid inactivity due to idle timeout.\n",
        "\n",
        "import IPython\n",
        "from IPython.display import clear_output\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function connectRefresher() {\n",
        "       window.ConnectButtonIntervalId = setInterval(function ConnectButton(){\n",
        "                console.log(\"connected\");\n",
        "                document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "                document.querySelector(\"colab-sessions-dialog\").shadowRoot.querySelector(\"#footer > div > paper-button\").click();\n",
        "                console.log(\"closed the dialog!!\");\n",
        "            },60000);\n",
        "    }\n",
        "\n",
        " function clearRefresher() {\n",
        "           console.log(\"clear Interval called !!\");\n",
        "           clearInterval(window.ConnectButtonIntervalId);\n",
        "    }\n",
        "\n",
        " connectRefresher(); //to connect the refresher\n",
        " clearRefresher(); //to disconnect the refresher\n",
        "'''))\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rzI_UE2kfUER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c3b586-7f52-40b7-b640-148c4e09b058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title [1] Mount Google Drive\n",
        "clear_output()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WUVFNJ8omlD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a2174b-5a82-440b-b8c3-83ca875ac8bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'DAT' already exists and is not an empty directory.\n",
            "/content/DAT\n",
            "Installed at /content/DAT\n"
          ]
        }
      ],
      "source": [
        "#@title [2] Install DAT\n",
        "#@markdown This notebook uses the **DAT architecture** by Zheng Chen  \\\n",
        "#@markdown [DAT on GitHub](https://github.com/zhengchen1999/DAT)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "%cd /content\n",
        "!git clone https://github.com/zhengchen1999/DAT.git\n",
        "%cd /content/DAT\n",
        "!echo Installed at /content/DAT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [3] Install others\n",
        "!pip3 install -r requirements.txt\n",
        "!pip3 install -q spandrel gdown"
      ],
      "metadata": {
        "id": "IvU86a0a74Zq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb445ef9-4648-4e42-a613-d48a3a85e2a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting addict (from -r requirements.txt (line 1))\n",
            "  Using cached addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
            "Collecting lmdb (from -r requirements.txt (line 3))\n",
            "  Using cached lmdb-1.7.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.32.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.16.2)\n",
            "Collecting tb-nightly (from -r requirements.txt (line 11))\n",
            "  Using cached tb_nightly-2.21.0a20250926-py3-none-any.whl.metadata (1.9 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.8.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.8.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [4] Install model\n",
        "import ipywidgets as widgets\n",
        "clear_output()\n",
        "%mkdir /content/models\n",
        "%cd /content/models\n",
        "!gdown -q 1RKPvYnYp4xy_PLnHr3le92CarIgr1LbN #Manga Ora\n",
        "!gdown -q 1JLSbRRaaWSdndwcQP1n6xqwRteYxJr1R #DAT light x2\n",
        "print(\"Model(s) downloaded.\")"
      ],
      "metadata": {
        "id": "xJhsXS-w1tWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13593d21-fef3-4962-f699-e40a6c16abef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/models’: File exists\n",
            "/content/models\n",
            "Model(s) downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [6] Set input/output folder\n",
        "\n",
        "#Uncomment if use colab drive\n",
        "#input_folder = '/content/input'\n",
        "#output_folder = '/content/output'\n",
        "\n",
        "#Uncomment if mount Google drive\n",
        "input_folder = '/content/drive/MyDrive/Nnn/input'\n",
        "output_folder = '/content/drive/MyDrive/Nnn/output'\n"
      ],
      "metadata": {
        "id": "_yRmjEyqBf24"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2593782a",
        "outputId": "f7597853-24aa-4dc4-c082-f098ab451ca2"
      },
      "source": [
        "#@title [7] Actual upscaling work (specifically for manga)\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from spandrel import ModelLoader, ImageModelDescriptor\n",
        "from pathlib import Path\n",
        "\n",
        "#get all images's path\n",
        "images = [p for p in Path(input_folder).iterdir()\n",
        "          if p.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]]\n",
        "\n",
        "#Load model\n",
        "Model_Name = \"2x_Manga_Ora.pth\" #Mofify this if you use other model\n",
        "model_path = f\"/content/models/{Model_Name}\"\n",
        "\n",
        "# Check if model file exists\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Error: Model file not found at {model_path}\")\n",
        "else:\n",
        "    model = ModelLoader().load_from_file(model_path)\n",
        "    assert isinstance(model, ImageModelDescriptor)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda().eval()\n",
        "        device = 'cuda'\n",
        "    else:\n",
        "        model.eval()\n",
        "        device = 'cpu'\n",
        "        print(\"CUDA not available, using CPU.\")\n",
        "\n",
        "\n",
        "    for img_path in images:\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            print(f\"Warning: Could not load image {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # Convert image to RGB (spandrel requires RGB)\n",
        "        if len(image.shape) == 2:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        #convert to tensor\n",
        "        tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float() / 255\n",
        "\n",
        "        tensor = tensor.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            #inference\n",
        "            result = model(tensor)\n",
        "\n",
        "            # move result back to CPU before converting to numpy\n",
        "            result_image = (result.detach().cpu().squeeze().permute(1, 2, 0).numpy().clip(0, 1) * 255).round().astype(\n",
        "                'uint8')\n",
        "\n",
        "            # Convert result image to grayscale\n",
        "            result_image_gray = cv2.cvtColor(result_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            filename = os.path.basename(img_path)\n",
        "            output_path = os.path.join(output_folder, os.path.splitext(filename)[0] + \".png\")\n",
        "\n",
        "            # Create output folder if it doesn't exist\n",
        "            os.makedirs(output_folder, exist_ok=True)\n",
        "            cv2.imwrite(output_path, result_image_gray)\n",
        "            print(f'Upscaled and saved {filename} as grayscale PNG')\n",
        "    print(\"DONE\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upscaled and saved 4.jpg as grayscale PNG\n",
            "DONE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [Bonus] General upscale (not grayscale)\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from spandrel import ModelLoader, ImageModelDescriptor\n",
        "from pathlib import Path\n",
        "\n",
        "#get all images's path\n",
        "images = [p for p in Path(input_folder).iterdir()\n",
        "          if p.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]]\n",
        "\n",
        "#Load model\n",
        "Model_Name = \"DAT_light_x2.pth\" #Mofify this if you use other model\n",
        "model_path = f\"/content/models/{Model_Name}\"\n",
        "\n",
        "# Check if model file exists\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Error: Model file not found at {model_path}\")\n",
        "else:\n",
        "    model = ModelLoader().load_from_file(model_path)\n",
        "    assert isinstance(model, ImageModelDescriptor)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda().eval()\n",
        "        device = 'cuda'\n",
        "    else:\n",
        "        model.eval()\n",
        "        device = 'cpu'\n",
        "        print(\"CUDA not available, using CPU.\")\n",
        "\n",
        "\n",
        "    for img_path in images:\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            print(f\"Warning: Could not load image {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # Convert image to RGB (spandrel requires RGB)\n",
        "        if len(image.shape) == 2:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        #convert to tensor\n",
        "        tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float() / 255\n",
        "\n",
        "        tensor = tensor.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            #inference\n",
        "            result = model(tensor)\n",
        "\n",
        "            # move result back to CPU before converting to numpy\n",
        "            result_image = (result.detach().cpu().squeeze().permute(1, 2, 0).numpy().clip(0, 1) * 255).round().astype(\n",
        "                'uint8')\n",
        "\n",
        "            filename = os.path.basename(img_path)\n",
        "            output_path = os.path.join(output_folder, os.path.splitext(filename)[0] + \".png\")\n",
        "\n",
        "            # Create output folder if it doesn't exist\n",
        "            os.makedirs(output_folder, exist_ok=True)\n",
        "            cv2.imwrite(output_path, cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR))\n",
        "            print(f'Upscaled and saved {filename} as PNG')\n",
        "    print(\"DONE\")"
      ],
      "metadata": {
        "id": "7m20SyoNf_QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "654f080e",
        "outputId": "1438548d-27f1-4fe8-e010-1b3ef081ecb6"
      },
      "source": [
        "#@title [Optional] Zip output folder for download if used colab's drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "output_folder = '/content/output'\n",
        "zip_file_name = '/content/output.zip'\n",
        "\n",
        "# Create the output folder if it doesn't exist (in case it was deleted)\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Zip the contents of the output folder\n",
        "shutil.make_archive(zip_file_name.replace('.zip', ''), 'zip', output_folder)\n",
        "\n",
        "print(f'Successfully zipped {output_folder} to {zip_file_name}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully zipped /content/output to /content/output.zip\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}